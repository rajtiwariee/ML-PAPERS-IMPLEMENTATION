{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e2cd10c",
   "metadata": {},
   "source": [
    "### ROPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d899481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "# type(nn.Linear())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28c33c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "033fd56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 6\n",
    "mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88f73360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c099a62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2201,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
       "        [ 1.3764,  0.6220,    -inf,    -inf,    -inf,    -inf],\n",
       "        [ 0.2803,  0.1554, -0.7288,    -inf,    -inf,    -inf],\n",
       "        [ 0.3666, -0.3853,  0.4477,  1.3087,    -inf,    -inf],\n",
       "        [-0.2056,  0.9088, -0.8399, -0.2532, -0.4475,    -inf],\n",
       "        [ 0.1551,  0.0405, -0.5983,  0.3143,  0.9515,  0.0617]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = torch.randn(seq_len,seq_len)\n",
    "scores+mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28bcfef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.309573444801933"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = 8\n",
    "(torch.arange(0, dim, 2).float() / dim)\n",
    "\n",
    "theta = 10_000\n",
    "\n",
    "theta**0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c07aa6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.1000, 0.0100, 0.0010])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dim = 8\n",
    "theta = 10_000\n",
    "freqs = 1.0 / (theta ** (torch.arange(0, dim, 2).float() / dim))\n",
    "freqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10dcaa28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.2500, 0.5000, 0.7500])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, dim, 2).float() /dim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "806d9e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
       "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
       "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
       "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
       "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
       "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
       "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
       "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
       "        126, 127])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end = 128 #max sequence size\n",
    "t = torch.arange(end, device=freqs.device)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf03a2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'cat', 'sat', 'on']\n",
      "['cat', 'sat', 'on', 'the']\n"
     ]
    }
   ],
   "source": [
    "text = ['The', 'cat', 'sat', 'on', 'the', 'mat']\n",
    "buf = text\n",
    "print(text[0:3+1])\n",
    "print(buf[1:4+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60213d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1a9d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d394588e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.1000, 0.0100, 0.0010])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[1]*freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1da70b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0000, 0.1000, 0.0100, 0.0010]), 128)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs_u = torch.outer(t, freqs).float()\n",
    "freqs_u[1], len(freqs_u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2d6a0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs_u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c367d41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.4161+0.9093j,  0.9801+0.1987j,  0.9998+0.0200j,  1.0000+0.0020j]),\n",
       " 128)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.polar(torch.ones_like(freqs_u), freqs_u)  # complex64\n",
    "x[2], len(x) #this is basically like generating angle for each pair of dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2e047256",
   "metadata": {},
   "outputs": [],
   "source": [
    "xq = torch.randn(128,4,8) # batchsize, seq_len, num_heads, head_dim\n",
    "xk = torch.randn(xq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "60204b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "##apply rotatory embedding\n",
    "xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2)) # (Seq, N_Heads, Head_Dim) --> (Seq, N_Heads, Head_Dim // 2)\n",
    "xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2)) # (Seq, N_Heads, Head_Dim) --> (Seq, N_Heads, Head_Dim // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "644bb1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 4, 4])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xq_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9d23f9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[1.0000e+00, 1.0000e-01, 1.0000e-02, 1.0000e-03]],\n",
       "\n",
       "        [[2.0000e+00, 2.0000e-01, 2.0000e-02, 2.0000e-03]],\n",
       "\n",
       "        [[3.0000e+00, 3.0000e-01, 3.0000e-02, 3.0000e-03]],\n",
       "\n",
       "        [[4.0000e+00, 4.0000e-01, 4.0000e-02, 4.0000e-03]],\n",
       "\n",
       "        [[5.0000e+00, 5.0000e-01, 5.0000e-02, 5.0000e-03]],\n",
       "\n",
       "        [[6.0000e+00, 6.0000e-01, 6.0000e-02, 6.0000e-03]],\n",
       "\n",
       "        [[7.0000e+00, 7.0000e-01, 7.0000e-02, 7.0000e-03]],\n",
       "\n",
       "        [[8.0000e+00, 8.0000e-01, 8.0000e-02, 8.0000e-03]],\n",
       "\n",
       "        [[9.0000e+00, 9.0000e-01, 9.0000e-02, 9.0000e-03]],\n",
       "\n",
       "        [[1.0000e+01, 1.0000e+00, 1.0000e-01, 1.0000e-02]],\n",
       "\n",
       "        [[1.1000e+01, 1.1000e+00, 1.1000e-01, 1.1000e-02]],\n",
       "\n",
       "        [[1.2000e+01, 1.2000e+00, 1.2000e-01, 1.2000e-02]],\n",
       "\n",
       "        [[1.3000e+01, 1.3000e+00, 1.3000e-01, 1.3000e-02]],\n",
       "\n",
       "        [[1.4000e+01, 1.4000e+00, 1.4000e-01, 1.4000e-02]],\n",
       "\n",
       "        [[1.5000e+01, 1.5000e+00, 1.5000e-01, 1.5000e-02]],\n",
       "\n",
       "        [[1.6000e+01, 1.6000e+00, 1.6000e-01, 1.6000e-02]],\n",
       "\n",
       "        [[1.7000e+01, 1.7000e+00, 1.7000e-01, 1.7000e-02]],\n",
       "\n",
       "        [[1.8000e+01, 1.8000e+00, 1.8000e-01, 1.8000e-02]],\n",
       "\n",
       "        [[1.9000e+01, 1.9000e+00, 1.9000e-01, 1.9000e-02]],\n",
       "\n",
       "        [[2.0000e+01, 2.0000e+00, 2.0000e-01, 2.0000e-02]],\n",
       "\n",
       "        [[2.1000e+01, 2.1000e+00, 2.1000e-01, 2.1000e-02]],\n",
       "\n",
       "        [[2.2000e+01, 2.2000e+00, 2.2000e-01, 2.2000e-02]],\n",
       "\n",
       "        [[2.3000e+01, 2.3000e+00, 2.3000e-01, 2.3000e-02]],\n",
       "\n",
       "        [[2.4000e+01, 2.4000e+00, 2.4000e-01, 2.4000e-02]],\n",
       "\n",
       "        [[2.5000e+01, 2.5000e+00, 2.5000e-01, 2.5000e-02]],\n",
       "\n",
       "        [[2.6000e+01, 2.6000e+00, 2.6000e-01, 2.6000e-02]],\n",
       "\n",
       "        [[2.7000e+01, 2.7000e+00, 2.7000e-01, 2.7000e-02]],\n",
       "\n",
       "        [[2.8000e+01, 2.8000e+00, 2.8000e-01, 2.8000e-02]],\n",
       "\n",
       "        [[2.9000e+01, 2.9000e+00, 2.9000e-01, 2.9000e-02]],\n",
       "\n",
       "        [[3.0000e+01, 3.0000e+00, 3.0000e-01, 3.0000e-02]],\n",
       "\n",
       "        [[3.1000e+01, 3.1000e+00, 3.1000e-01, 3.1000e-02]],\n",
       "\n",
       "        [[3.2000e+01, 3.2000e+00, 3.2000e-01, 3.2000e-02]],\n",
       "\n",
       "        [[3.3000e+01, 3.3000e+00, 3.3000e-01, 3.3000e-02]],\n",
       "\n",
       "        [[3.4000e+01, 3.4000e+00, 3.4000e-01, 3.4000e-02]],\n",
       "\n",
       "        [[3.5000e+01, 3.5000e+00, 3.5000e-01, 3.5000e-02]],\n",
       "\n",
       "        [[3.6000e+01, 3.6000e+00, 3.6000e-01, 3.6000e-02]],\n",
       "\n",
       "        [[3.7000e+01, 3.7000e+00, 3.7000e-01, 3.7000e-02]],\n",
       "\n",
       "        [[3.8000e+01, 3.8000e+00, 3.8000e-01, 3.8000e-02]],\n",
       "\n",
       "        [[3.9000e+01, 3.9000e+00, 3.9000e-01, 3.9000e-02]],\n",
       "\n",
       "        [[4.0000e+01, 4.0000e+00, 4.0000e-01, 4.0000e-02]],\n",
       "\n",
       "        [[4.1000e+01, 4.1000e+00, 4.1000e-01, 4.1000e-02]],\n",
       "\n",
       "        [[4.2000e+01, 4.2000e+00, 4.2000e-01, 4.2000e-02]],\n",
       "\n",
       "        [[4.3000e+01, 4.3000e+00, 4.3000e-01, 4.3000e-02]],\n",
       "\n",
       "        [[4.4000e+01, 4.4000e+00, 4.4000e-01, 4.4000e-02]],\n",
       "\n",
       "        [[4.5000e+01, 4.5000e+00, 4.5000e-01, 4.5000e-02]],\n",
       "\n",
       "        [[4.6000e+01, 4.6000e+00, 4.6000e-01, 4.6000e-02]],\n",
       "\n",
       "        [[4.7000e+01, 4.7000e+00, 4.7000e-01, 4.7000e-02]],\n",
       "\n",
       "        [[4.8000e+01, 4.8000e+00, 4.8000e-01, 4.8000e-02]],\n",
       "\n",
       "        [[4.9000e+01, 4.9000e+00, 4.9000e-01, 4.9000e-02]],\n",
       "\n",
       "        [[5.0000e+01, 5.0000e+00, 5.0000e-01, 5.0000e-02]],\n",
       "\n",
       "        [[5.1000e+01, 5.1000e+00, 5.1000e-01, 5.1000e-02]],\n",
       "\n",
       "        [[5.2000e+01, 5.2000e+00, 5.2000e-01, 5.2000e-02]],\n",
       "\n",
       "        [[5.3000e+01, 5.3000e+00, 5.3000e-01, 5.3000e-02]],\n",
       "\n",
       "        [[5.4000e+01, 5.4000e+00, 5.4000e-01, 5.4000e-02]],\n",
       "\n",
       "        [[5.5000e+01, 5.5000e+00, 5.5000e-01, 5.5000e-02]],\n",
       "\n",
       "        [[5.6000e+01, 5.6000e+00, 5.6000e-01, 5.6000e-02]],\n",
       "\n",
       "        [[5.7000e+01, 5.7000e+00, 5.7000e-01, 5.7000e-02]],\n",
       "\n",
       "        [[5.8000e+01, 5.8000e+00, 5.8000e-01, 5.8000e-02]],\n",
       "\n",
       "        [[5.9000e+01, 5.9000e+00, 5.9000e-01, 5.9000e-02]],\n",
       "\n",
       "        [[6.0000e+01, 6.0000e+00, 6.0000e-01, 6.0000e-02]],\n",
       "\n",
       "        [[6.1000e+01, 6.1000e+00, 6.1000e-01, 6.1000e-02]],\n",
       "\n",
       "        [[6.2000e+01, 6.2000e+00, 6.2000e-01, 6.2000e-02]],\n",
       "\n",
       "        [[6.3000e+01, 6.3000e+00, 6.3000e-01, 6.3000e-02]],\n",
       "\n",
       "        [[6.4000e+01, 6.4000e+00, 6.4000e-01, 6.4000e-02]],\n",
       "\n",
       "        [[6.5000e+01, 6.5000e+00, 6.5000e-01, 6.5000e-02]],\n",
       "\n",
       "        [[6.6000e+01, 6.6000e+00, 6.6000e-01, 6.6000e-02]],\n",
       "\n",
       "        [[6.7000e+01, 6.7000e+00, 6.7000e-01, 6.7000e-02]],\n",
       "\n",
       "        [[6.8000e+01, 6.8000e+00, 6.8000e-01, 6.8000e-02]],\n",
       "\n",
       "        [[6.9000e+01, 6.9000e+00, 6.9000e-01, 6.9000e-02]],\n",
       "\n",
       "        [[7.0000e+01, 7.0000e+00, 7.0000e-01, 7.0000e-02]],\n",
       "\n",
       "        [[7.1000e+01, 7.1000e+00, 7.1000e-01, 7.1000e-02]],\n",
       "\n",
       "        [[7.2000e+01, 7.2000e+00, 7.2000e-01, 7.2000e-02]],\n",
       "\n",
       "        [[7.3000e+01, 7.3000e+00, 7.3000e-01, 7.3000e-02]],\n",
       "\n",
       "        [[7.4000e+01, 7.4000e+00, 7.4000e-01, 7.4000e-02]],\n",
       "\n",
       "        [[7.5000e+01, 7.5000e+00, 7.5000e-01, 7.5000e-02]],\n",
       "\n",
       "        [[7.6000e+01, 7.6000e+00, 7.6000e-01, 7.6000e-02]],\n",
       "\n",
       "        [[7.7000e+01, 7.7000e+00, 7.7000e-01, 7.7000e-02]],\n",
       "\n",
       "        [[7.8000e+01, 7.8000e+00, 7.8000e-01, 7.8000e-02]],\n",
       "\n",
       "        [[7.9000e+01, 7.9000e+00, 7.9000e-01, 7.9000e-02]],\n",
       "\n",
       "        [[8.0000e+01, 8.0000e+00, 8.0000e-01, 8.0000e-02]],\n",
       "\n",
       "        [[8.1000e+01, 8.1000e+00, 8.1000e-01, 8.1000e-02]],\n",
       "\n",
       "        [[8.2000e+01, 8.2000e+00, 8.2000e-01, 8.2000e-02]],\n",
       "\n",
       "        [[8.3000e+01, 8.3000e+00, 8.3000e-01, 8.3000e-02]],\n",
       "\n",
       "        [[8.4000e+01, 8.4000e+00, 8.4000e-01, 8.4000e-02]],\n",
       "\n",
       "        [[8.5000e+01, 8.5000e+00, 8.5000e-01, 8.5000e-02]],\n",
       "\n",
       "        [[8.6000e+01, 8.6000e+00, 8.6000e-01, 8.6000e-02]],\n",
       "\n",
       "        [[8.7000e+01, 8.7000e+00, 8.7000e-01, 8.7000e-02]],\n",
       "\n",
       "        [[8.8000e+01, 8.8000e+00, 8.8000e-01, 8.8000e-02]],\n",
       "\n",
       "        [[8.9000e+01, 8.9000e+00, 8.9000e-01, 8.9000e-02]],\n",
       "\n",
       "        [[9.0000e+01, 9.0000e+00, 9.0000e-01, 9.0000e-02]],\n",
       "\n",
       "        [[9.1000e+01, 9.1000e+00, 9.1000e-01, 9.1000e-02]],\n",
       "\n",
       "        [[9.2000e+01, 9.2000e+00, 9.2000e-01, 9.2000e-02]],\n",
       "\n",
       "        [[9.3000e+01, 9.3000e+00, 9.3000e-01, 9.3000e-02]],\n",
       "\n",
       "        [[9.4000e+01, 9.4000e+00, 9.4000e-01, 9.4000e-02]],\n",
       "\n",
       "        [[9.5000e+01, 9.5000e+00, 9.5000e-01, 9.5000e-02]],\n",
       "\n",
       "        [[9.6000e+01, 9.6000e+00, 9.6000e-01, 9.6000e-02]],\n",
       "\n",
       "        [[9.7000e+01, 9.7000e+00, 9.7000e-01, 9.7000e-02]],\n",
       "\n",
       "        [[9.8000e+01, 9.8000e+00, 9.8000e-01, 9.8000e-02]],\n",
       "\n",
       "        [[9.9000e+01, 9.9000e+00, 9.9000e-01, 9.9000e-02]],\n",
       "\n",
       "        [[1.0000e+02, 1.0000e+01, 1.0000e+00, 1.0000e-01]],\n",
       "\n",
       "        [[1.0100e+02, 1.0100e+01, 1.0100e+00, 1.0100e-01]],\n",
       "\n",
       "        [[1.0200e+02, 1.0200e+01, 1.0200e+00, 1.0200e-01]],\n",
       "\n",
       "        [[1.0300e+02, 1.0300e+01, 1.0300e+00, 1.0300e-01]],\n",
       "\n",
       "        [[1.0400e+02, 1.0400e+01, 1.0400e+00, 1.0400e-01]],\n",
       "\n",
       "        [[1.0500e+02, 1.0500e+01, 1.0500e+00, 1.0500e-01]],\n",
       "\n",
       "        [[1.0600e+02, 1.0600e+01, 1.0600e+00, 1.0600e-01]],\n",
       "\n",
       "        [[1.0700e+02, 1.0700e+01, 1.0700e+00, 1.0700e-01]],\n",
       "\n",
       "        [[1.0800e+02, 1.0800e+01, 1.0800e+00, 1.0800e-01]],\n",
       "\n",
       "        [[1.0900e+02, 1.0900e+01, 1.0900e+00, 1.0900e-01]],\n",
       "\n",
       "        [[1.1000e+02, 1.1000e+01, 1.1000e+00, 1.1000e-01]],\n",
       "\n",
       "        [[1.1100e+02, 1.1100e+01, 1.1100e+00, 1.1100e-01]],\n",
       "\n",
       "        [[1.1200e+02, 1.1200e+01, 1.1200e+00, 1.1200e-01]],\n",
       "\n",
       "        [[1.1300e+02, 1.1300e+01, 1.1300e+00, 1.1300e-01]],\n",
       "\n",
       "        [[1.1400e+02, 1.1400e+01, 1.1400e+00, 1.1400e-01]],\n",
       "\n",
       "        [[1.1500e+02, 1.1500e+01, 1.1500e+00, 1.1500e-01]],\n",
       "\n",
       "        [[1.1600e+02, 1.1600e+01, 1.1600e+00, 1.1600e-01]],\n",
       "\n",
       "        [[1.1700e+02, 1.1700e+01, 1.1700e+00, 1.1700e-01]],\n",
       "\n",
       "        [[1.1800e+02, 1.1800e+01, 1.1800e+00, 1.1800e-01]],\n",
       "\n",
       "        [[1.1900e+02, 1.1900e+01, 1.1900e+00, 1.1900e-01]],\n",
       "\n",
       "        [[1.2000e+02, 1.2000e+01, 1.2000e+00, 1.2000e-01]],\n",
       "\n",
       "        [[1.2100e+02, 1.2100e+01, 1.2100e+00, 1.2100e-01]],\n",
       "\n",
       "        [[1.2200e+02, 1.2200e+01, 1.2200e+00, 1.2200e-01]],\n",
       "\n",
       "        [[1.2300e+02, 1.2300e+01, 1.2300e+00, 1.2300e-01]],\n",
       "\n",
       "        [[1.2400e+02, 1.2400e+01, 1.2400e+00, 1.2400e-01]],\n",
       "\n",
       "        [[1.2500e+02, 1.2500e+01, 1.2500e+00, 1.2500e-01]],\n",
       "\n",
       "        [[1.2600e+02, 1.2600e+01, 1.2600e+00, 1.2600e-01]],\n",
       "\n",
       "        [[1.2700e+02, 1.2700e+01, 1.2700e+00, 1.2700e-01]]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs_cis = freqs_u[:, None, :]       # (L, 1, D/2)\n",
    "freqs_cis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "78a799c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 4, 4]), torch.Size([128, 1, 4]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xq_.shape,freqs_cis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e11b14e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.view_as_real(xq_[0]*freqs_cis[0]).flatten(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ad64ebaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00, -0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00, -0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[-0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00, -0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00],\n",
       "          [-0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[-0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00, -0.0000e+00],\n",
       "          [-0.0000e+00,  0.0000e+00],\n",
       "          [-0.0000e+00,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[-4.4467e-01,  1.2905e+00],\n",
       "          [ 9.8830e-02, -1.0726e-01],\n",
       "          [ 6.8933e-03, -6.3250e-03],\n",
       "          [-2.2125e-04, -1.2586e-04]],\n",
       "\n",
       "         [[-9.7308e-01,  2.4362e-01],\n",
       "          [ 6.7896e-02,  5.7896e-02],\n",
       "          [ 2.2173e-03, -1.1317e-02],\n",
       "          [-1.2682e-03, -1.5833e-04]],\n",
       "\n",
       "         [[ 4.7539e-01,  9.4646e-01],\n",
       "          [ 3.7943e-02,  8.8356e-03],\n",
       "          [ 5.2281e-03, -1.0338e-03],\n",
       "          [-2.4450e-03,  6.0676e-04]],\n",
       "\n",
       "         [[ 1.4023e+00,  8.6255e-02],\n",
       "          [ 4.8768e-02,  1.1965e-01],\n",
       "          [-2.8240e-04,  1.6889e-03],\n",
       "          [ 1.9652e-03, -8.0852e-05]]],\n",
       "\n",
       "\n",
       "        [[[ 2.8526e+00,  2.1159e+00],\n",
       "          [ 8.8135e-02, -8.5195e-02],\n",
       "          [ 2.1861e-02,  4.8082e-02],\n",
       "          [-1.5402e-03,  1.2134e-03]],\n",
       "\n",
       "         [[-2.0926e+00, -5.6686e-01],\n",
       "          [-1.9291e-01, -2.1124e-01],\n",
       "          [-1.9912e-02,  8.1574e-03],\n",
       "          [ 2.0572e-03,  1.0505e-03]],\n",
       "\n",
       "         [[-1.9909e+00, -5.8279e-02],\n",
       "          [ 2.3187e-01,  7.5195e-02],\n",
       "          [-7.5561e-03, -7.9550e-03],\n",
       "          [-1.6318e-03, -1.9349e-03]],\n",
       "\n",
       "         [[ 2.2884e+00,  9.7727e-01],\n",
       "          [ 2.0101e-01, -5.7294e-02],\n",
       "          [ 4.1133e-02, -1.5826e-02],\n",
       "          [ 2.3104e-04,  1.3521e-03]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-1.0672e+02, -9.8233e+01],\n",
       "          [ 1.8190e+01,  1.9542e+01],\n",
       "          [-8.9335e-01,  1.3324e+00],\n",
       "          [ 1.1258e-01, -7.1248e-02]],\n",
       "\n",
       "         [[ 2.3300e+02,  7.4832e+00],\n",
       "          [-1.4970e+00, -6.7742e+00],\n",
       "          [-6.9306e-01, -2.3363e-01],\n",
       "          [-9.9841e-02, -5.1291e-02]],\n",
       "\n",
       "         [[ 1.6604e+02,  6.5619e+01],\n",
       "          [ 1.4196e+01,  4.1818e+00],\n",
       "          [ 1.0282e+00, -1.4877e+00],\n",
       "          [-8.0830e-02, -2.5371e-01]],\n",
       "\n",
       "         [[ 9.9168e+01,  9.8310e+01],\n",
       "          [-1.0520e+01,  6.7216e+00],\n",
       "          [ 1.0951e+00, -2.0271e+00],\n",
       "          [-3.9077e-02, -1.5809e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.9864e+01,  2.9236e+01],\n",
       "          [-3.5669e+00, -6.0118e+00],\n",
       "          [-3.0097e-01,  9.9035e-01],\n",
       "          [ 1.2685e-01, -8.9460e-03]],\n",
       "\n",
       "         [[-1.7509e+02,  1.0989e+02],\n",
       "          [-6.1719e+00,  4.3122e+00],\n",
       "          [ 9.6860e-02, -1.5378e-01],\n",
       "          [ 9.9677e-02, -8.3648e-02]],\n",
       "\n",
       "         [[-1.6081e+02, -5.1624e+01],\n",
       "          [ 1.1817e+00, -1.2528e+01],\n",
       "          [-2.0591e+00,  6.5811e-01],\n",
       "          [-5.9902e-02,  3.9339e-03]],\n",
       "\n",
       "         [[-1.1672e+02, -1.6448e+01],\n",
       "          [ 1.6861e+01, -1.2221e+01],\n",
       "          [ 2.9942e+00, -8.4024e-01],\n",
       "          [-2.2740e-02, -1.8056e-01]]],\n",
       "\n",
       "\n",
       "        [[[-6.6839e+00,  2.1629e+02],\n",
       "          [-4.0088e+00, -2.2074e+00],\n",
       "          [-1.1652e+00,  1.5436e+00],\n",
       "          [ 1.4879e-01,  1.8055e-01]],\n",
       "\n",
       "         [[ 9.4832e+01,  1.4112e+02],\n",
       "          [-6.1280e+00,  2.3099e+00],\n",
       "          [-2.1652e+00, -5.9145e-01],\n",
       "          [-4.8932e-02, -1.0846e-01]],\n",
       "\n",
       "         [[ 1.5651e+02, -5.0702e+01],\n",
       "          [ 1.7469e+01, -1.2593e+00],\n",
       "          [ 2.3721e+00,  1.2855e+00],\n",
       "          [-1.2136e-01, -6.6351e-03]],\n",
       "\n",
       "         [[-1.2370e+01, -6.1466e+01],\n",
       "          [ 1.0903e+01,  3.6855e+00],\n",
       "          [-1.0640e+00,  6.6658e-01],\n",
       "          [ 1.2190e-02, -8.1537e-02]]]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.view_as_real(xq_ * freqs_cis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ac82b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 4, 8])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(2)\n",
    "xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(2)\n",
    "\n",
    "\n",
    "xq_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae6a027",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9764fe04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/torch/_subclasses/functional_tensor.py:276: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[[-0.4533, -0.3675, -0.1270,  1.1463, -0.2604,  0.0926,  0.9946],\n",
       "           [-0.4162,  1.8222,  0.4044, -0.2206,  0.1385, -2.9662,  0.1371]],\n",
       "\n",
       "          [[-1.2895,  0.1460,  0.7678,  1.8731,  1.3455,  1.1769,  0.5677],\n",
       "           [ 1.0320, -0.2058, -0.0978, -1.6889, -0.4842,  1.1899, -0.6999]],\n",
       "\n",
       "          [[-2.3260, -1.3848, -0.0641, -1.5364,  0.2893,  0.1010, -1.7162],\n",
       "           [ 1.7862, -0.0540, -0.4318, -0.2321,  0.1171, -0.7251, -1.6531]]],\n",
       "\n",
       "\n",
       "         [[[ 0.4898, -0.2573, -0.3233,  0.2182,  0.2094,  0.6430, -0.7222],\n",
       "           [-0.0053,  0.4473, -1.0618, -0.5134,  0.1241, -1.7960, -0.9455]],\n",
       "\n",
       "          [[-0.0352, -1.6997, -0.2395, -0.4203,  0.2276, -0.6762,  1.9303],\n",
       "           [-0.3389, -0.2476,  1.1896, -0.5112, -0.0305,  0.4175, -0.9804]],\n",
       "\n",
       "          [[-0.5624,  0.6293, -0.4875, -1.2859,  0.8312,  0.3315,  0.0638],\n",
       "           [-0.1799,  1.4999, -0.0130,  0.3338,  0.5623,  1.0163, -0.3292]]]]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.randn(1,2,3,2,7)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3c1dc98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.5133,  1.0696, -1.0343,  0.7257],\n",
       "          [-0.1375,  0.6273, -1.0861, -0.0903]],\n",
       "\n",
       "         [[-1.2342,  1.5384, -2.2976,  1.0724],\n",
       "          [-1.2737, -0.6474,  0.0996,  1.6319]],\n",
       "\n",
       "         [[-0.7280,  1.4553, -1.0420,  0.6409],\n",
       "          [-0.5856, -0.5049, -2.0347,  0.0171]]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(1,3,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3139c7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "mask=torch.tril(torch.ones(5,5,device='mps'))\n",
    "mask=mask[-1]\n",
    "# mask=mask.view(1,1,1,window_size).expand(batch_size,num_heads,seq_len,window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb423774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.], device='mps:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ac84f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       "\n",
       "         [[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       "\n",
       "         [[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]],\n",
       "\n",
       "         [[1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1.]]]], device='mps:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask=mask.view(1,1,1,5).expand(1,4,3,5)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20114661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.13.3 environment at: /Library/Frameworks/Python.framework/Versions/3.13\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m9 packages\u001b[0m \u001b[2min 233ms\u001b[0m\u001b[0m                                         \u001b[0m\n",
      "\u001b[2K\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m     0 B/984.25 KiB                    \u001b[1A\n",
      "\u001b[2mregex     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/277.95 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m     0 B/984.25 KiB                    \u001b[2A\n",
      "\u001b[2mregex     \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/277.95 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m     0 B/984.25 KiB                    \u001b[2A\n",
      "\u001b[2mregex     \u001b[0m \u001b[32m--\u001b[2m----------------------------\u001b[0m\u001b[0m 16.00 KiB/277.95 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 8.74 KiB/984.25 KiB                   \u001b[2A\n",
      "\u001b[2mregex     \u001b[0m \u001b[32m----\u001b[2m--------------------------\u001b[0m\u001b[0m 32.00 KiB/277.95 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 8.74 KiB/984.25 KiB                   \u001b[2A\n",
      "\u001b[2mregex     \u001b[0m \u001b[32m------\u001b[2m------------------------\u001b[0m\u001b[0m 48.00 KiB/277.95 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 8.74 KiB/984.25 KiB                   \u001b[2A\n",
      "\u001b[2mregex     \u001b[0m \u001b[32m-------\u001b[2m-----------------------\u001b[0m\u001b[0m 64.00 KiB/277.95 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 8.74 KiB/984.25 KiB                   \u001b[2A\n",
      "\u001b[2mregex     \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 80.00 KiB/277.95 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 8.74 KiB/984.25 KiB                   \u001b[2A\n",
      "\u001b[2mregex     \u001b[0m \u001b[32m---------\u001b[2m---------------------\u001b[0m\u001b[0m 80.00 KiB/277.95 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 24.74 KiB/984.25 KiB                  \u001b[2A\n",
      "\u001b[2mregex     \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 96.00 KiB/277.95 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 24.74 KiB/984.25 KiB                  \u001b[2A\n",
      "\u001b[2mregex     \u001b[0m \u001b[32m-----------\u001b[2m-------------------\u001b[0m\u001b[0m 96.00 KiB/277.95 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 40.74 KiB/984.25 KiB                  \u001b[2A\n",
      "\u001b[2mregex     \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 112.00 KiB/277.95 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 40.74 KiB/984.25 KiB                  \u001b[2A\n",
      "\u001b[2mregex     \u001b[0m \u001b[32m-------------\u001b[2m-----------------\u001b[0m\u001b[0m 112.00 KiB/277.95 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 56.74 KiB/984.25 KiB                  \u001b[2A\n",
      "\u001b[2mregex     \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 128.00 KiB/277.95 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 56.74 KiB/984.25 KiB                  \u001b[2A\n",
      "\u001b[2mregex     \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 128.00 KiB/277.95 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 63.27 KiB/984.25 KiB                  \u001b[2A\n",
      "\u001b[2mcharset-normalizer\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/194.94 KiB\n",
      "\u001b[2mregex     \u001b[0m \u001b[32m--------------\u001b[2m----------------\u001b[0m\u001b[0m 128.00 KiB/277.95 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 63.27 KiB/984.25 KiB                  \u001b[3A\n",
      "\u001b[2mcharset-normalizer\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/194.94 KiB\n",
      "\u001b[2mregex     \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 144.00 KiB/277.95 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 63.27 KiB/984.25 KiB                  \u001b[3A\n",
      "\u001b[2mcharset-normalizer\u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/194.94 KiB\n",
      "\u001b[2mregex     \u001b[0m \u001b[32m----------------\u001b[2m--------------\u001b[0m\u001b[0m 144.00 KiB/277.95 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 79.27 KiB/984.25 KiB                  \u001b[3A\n",
      "\u001b[2mcharset-normalizer\u001b[0m \u001b[32m--------\u001b[2m----------------------\u001b[0m\u001b[0m 48.00 KiB/194.94 KiB\n",
      "\u001b[2mregex     \u001b[0m \u001b[32m-------------------------\u001b[2m-----\u001b[0m\u001b[0m 224.00 KiB/277.95 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 112.75 KiB/984.25 KiB                 \u001b[3A\n",
      "\u001b[2mcharset-normalizer\u001b[0m \u001b[32m---------------\u001b[2m---------------\u001b[0m\u001b[0m 96.00 KiB/194.94 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠙\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 160.75 KiB/984.25 KiB                 \u001b[2A\n",
      "\u001b[2mcharset-normalizer\u001b[0m \u001b[32m--------------------\u001b[2m----------\u001b[0m\u001b[0m 128.00 KiB/194.94 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/3)----\u001b[0m\u001b[0m 224.75 KiB/984.25 KiB                 \u001b[2A\n",
      "\u001b[2mcharset-normalizer\u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 192.00 KiB/194.94 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/3)----\u001b[0m\u001b[0m 304.75 KiB/984.25 KiB                 \u001b[2A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/3)----\u001b[0m\u001b[0m 336.75 KiB/984.25 KiB                 \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/3)----\u001b[0m\u001b[0m 432.75 KiB/984.25 KiB                 \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m⠹\u001b[0m \u001b[2mPreparing packages...\u001b[0m (1/3)----\u001b[0m\u001b[0m 560.75 KiB/984.25 KiB                 \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 399ms\u001b[0m\u001b[0m                                                 \u001b[1A\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m7 packages\u001b[0m \u001b[2min 7ms\u001b[0m\u001b[0m3.4.2                            \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.4.26\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2024.11.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtiktoken\u001b[0m\u001b[2m==0.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.4.0\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%uv pip install torchinfo tqdm tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685e340e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f933bd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "from model import minimixtral\n",
    "from config import ModelArgs, MoeArgs\n",
    "\n",
    "\n",
    "args = ModelArgs(vocab_size=50257,moe=MoeArgs())\n",
    "mini_mistral = minimixtral(args)\n",
    "\n",
    "# summary(mini_mistral,input_size=(4,256,512))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fafd8b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 195,433,105\n",
      "Trainable parameters: 195,433,105\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {total:,}\")\n",
    "    print(f\"Trainable parameters: {trainable:,}\")\n",
    "\n",
    "# Example usage\n",
    "count_parameters(mini_mistral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7eb6ee06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ckpts/best_step124.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- completion ---\n",
      "<|endoftext|> pharmaceutical far dice time, but he Then oldOK, but he could help saw, but he had a big, but he had a big, but he happy thatGoode, but they it doing on, but she could matching she desk, Mom had a big, laughed you noticed wand, he had you out of is this, she saw a time, for, she looked finding had a adventure, that he she garden, built, that you help, You of play his mom hands, \" looked he hugs sound, child, but he would, she saw he Mia, hugged, I are\n",
      "\n",
      "\n",
      "--- completion ---\n",
      "<|endoftext|>Once falling, but be look they picked, but it too had a big, but\n",
      "\n",
      "\n",
      "--- completion ---\n",
      "<|endoftext|>Tom, but he said, but she island, but it, but was so, ruined, thought, has, Lily, there, snake, they, you, she, they you, lots of would, Lily, Lily, Lily, of, she towards, Lily, they, Lily, Lily, she cooking, you morning,, Lily, chocolate, all, I, she, she had that, she, Lily, stopped, opened, he an, don, they were, he heard, Lily, she, until, she sw, she, heNo, Lily, she why,\n",
      "\n",
      "\n",
      "--- completion ---\n",
      "<|endoftext|>™, but he does Bob things, but she I never that she Bella, he every every, there, he could Max it, but he had doing careful, but he dangerous?\" even, she had so also But fun, Lily she also so something, is get away, Lily, there, he could reached, she had shook, herself, fun, Lily, runs, something, Ben, want she had, she saw, they had, they had.\" they were, had a big, Lily, she did not they, Lily, she told, I, she Tom, mommy,\n",
      "\n",
      "\n",
      "--- completion ---\n",
      "<|endoftext|>One day, but, but she hot, but she each being, but he help, we as, but, he could pretty, should, whistle, Lily,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch, tiktoken, glob\n",
    "from torch.serialization import add_safe_globals\n",
    "from config import ModelArgs\n",
    "from model  import minimixtral           # your network\n",
    "from pathlib import Path\n",
    "# ── allow custom class in safe unpickler ───────────────────────\n",
    "add_safe_globals([ModelArgs])\n",
    "\n",
    "# ckpt_path = sorted(glob.glob(\"ckpts/*.pt\"))[0]\n",
    "ckpt_path = Path('ckpts/best_step124.pt')\n",
    "\n",
    "print(\"Loading\", ckpt_path)\n",
    "\n",
    "# 1) load on CPU\n",
    "ckpt = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)\n",
    "args = ckpt[\"args\"]\n",
    "\n",
    "# 2) make constructor stay on CPU\n",
    "args.device = \"cpu\"                      # ← critical line\n",
    "\n",
    "model = minimixtral(args)                # no CUDA tensors yet\n",
    "model.load_state_dict(ckpt[\"model\"], strict=False)\n",
    "\n",
    "# 3) optionally move to GPU once, safely\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(\"cpu\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# 4) ready to generate\n",
    "tok  = tiktoken.get_encoding(\"gpt2\")\n",
    "EOT  = tok._special_tokens[\"<|endoftext|>\"]\n",
    "\n",
    "def encode(t): return tok.encode_ordinary(t)\n",
    "def decode(i): return tok.decode(i)\n",
    "\n",
    "@torch.no_grad()\n",
    "def complete(prompt, max_new=120, temp=0.8, top_p=0.9):\n",
    "    dv  = next(model.parameters()).device\n",
    "    ids = torch.tensor(encode(prompt)+[EOT], device=dv)\n",
    "\n",
    "    for _ in range(max_new):\n",
    "        logits = model(ids.unsqueeze(0), 0)[0, -1] / temp\n",
    "        probs  = torch.softmax(logits, -1)\n",
    "\n",
    "        sorted_idx = torch.argsort(probs, descending=True)\n",
    "        cumsum     = torch.cumsum(probs[sorted_idx], 0)\n",
    "        keep       = cumsum <= top_p\n",
    "        keep[0]    = True\n",
    "        probs[sorted_idx[~keep]] = 0\n",
    "        probs /= probs.sum()\n",
    "\n",
    "        next_id = torch.multinomial(probs, 1)\n",
    "        if next_id.item() == EOT:\n",
    "            break\n",
    "        ids = torch.cat([ids, next_id])\n",
    "    return decode(ids.tolist()[len(encode(prompt)):])\n",
    "\n",
    "# quick demo\n",
    "for _ in range(5):\n",
    "    print(\"\\n--- completion ---\\n\" +\n",
    "        complete(\"Long time ago, \") + \"\\n\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a05e734",
   "metadata": {},
   "outputs": [],
   "source": [
    "--- completion ---\n",
    "<|endoftext|> painted down on, but he saw theyily they Thank, Toby you want Jane, but he also Mom, but he looked One, but it, but she open are walked, but he with triedYes, but she had after again, but he had of bounce, but he out what couldn't wear, but they ice garden, but, again going out, but he you too, sir, Lily table Can, she bottle, Lily so, or, on, we are, garden, she had you have, Lily, she hadNo, she remembered, Lily around, she who, Mom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68d51d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "--- completion ---\n",
    "<|endoftext|>Once upon a time there were two dragons they were so happy that he had name you only, but she could day, but he had a! He saw happened said that of talk toy heWhen had a big cake that he had a only some that she had a big, and be finished old am youHello off when will time sheOne day, but he tried you who lunch, he had a sky what that she took a big that she looked be very happy that he had a big you so they had a big soft, Lily that tried looked long is for. He would you can is Bob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34d41956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.30.2)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->huggingface_hub) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90722d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from huggingface_hub import PyTorchModelHubMixin\n",
    "\n",
    "\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()\n",
    "repo_id = \"rajtiwariee/my-manually-uploaded-model\"\n",
    "api.create_repo(repo_id=repo_id, private=False, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28521297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124fcdf6ebad4549ae59942695baf5e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "minimixtral.pt:   0%|          | 0.00/1.05G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ upload done!\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "import os\n",
    "\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")          # or paste the string here\n",
    "api      = HfApi(token=HF_TOKEN)\n",
    "\n",
    "repo_id = \"rajtiwariee/minimixtral\"       # <user>/<repo_name>\n",
    "\n",
    "# 1️⃣ create the repo once (does nothing if it already exists)\n",
    "api.create_repo(repo_id=repo_id,\n",
    "                repo_type=\"model\",\n",
    "                private=False,            # ↙ change if you want a private repo\n",
    "                exist_ok=True)\n",
    "\n",
    "# 2️⃣ now push your checkpoint folder\n",
    "api.upload_folder(\n",
    "    folder_path=\"ckpts/best\",             # local directory\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"model\"\n",
    ")\n",
    "print(\"✅ upload done!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
